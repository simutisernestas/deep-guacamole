{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import transforms3d as tf\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(labels_df)):\n",
    "#     minid = abs(events_df[\"timestamp\"]-labels_df.iloc[i][\"timestamp\"]).idxmin()\n",
    "#     labels_df[\"events_start_idx\"][i] = minid\n",
    "# labels_df.to_pickle(\"event_indexed_labels.pickle\")\n",
    "# DANGER: takes ~ 40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDataset(Dataset):\n",
    "    def __init__(self, data_dir, label_file, label_delta_len):\n",
    "        events_cols=[\"timestamp\", \"x\", \"y\", \"polarity\"]\n",
    "        self.events_df = pd.read_csv(os.path.join(data_dir,\"events.txt\"), delimiter=' ', skiprows=1, names=events_cols)\n",
    "        events_df_nostamp = self.events_df.loc[:, self.events_df.columns != 'timestamp']\n",
    "        self.events_data = torch.from_numpy(events_df_nostamp.to_numpy(dtype=np.float32))\n",
    "        \n",
    "        self.labels_df = pd.read_pickle(\"event_indexed_labels.pickle\")\n",
    "        labels_df_nostamp = self.labels_df.loc[:, self.labels_df.columns != 'timestamp']\n",
    "        labels_df_nostamp = labels_df_nostamp.loc[:, labels_df_nostamp.columns != 'events_start_idx']\n",
    "        self.labels = torch.tensor(labels_df_nostamp.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "        self.delta = label_delta_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0] - self.delta\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dpose = torch.zeros(7)\n",
    "        l1 = self.labels[idx]\n",
    "        l2 = self.labels[idx+self.delta]\n",
    "        dl = l2-l1 # position delta\n",
    "        dpose[:3] = dl[:3]\n",
    "        q1 = l1[3:][[3,0,1,2]] # rearange quaternion, w goes first\n",
    "        q2 = l2[3:][[3,0,1,2]] # rearange quaternion, w goes first\n",
    "        dq = tf.quaternions.qmult(q2, tf.quaternions.qinverse(q1)) # orientation delta\n",
    "        dpose[3:] = torch.tensor(dq, dtype=torch.float32) # pose delta is the label\n",
    "\n",
    "        start = self.labels_df.iloc[idx][\"events_start_idx\"]\n",
    "        finish = self.labels_df.iloc[idx+self.delta][\"events_start_idx\"]\n",
    "\n",
    "        # could highly optimize this : )\n",
    "        # torch version https://stackoverflow.com/questions/65584330/add-a-index-selected-tensor-to-another-tensor-with-overlapping-indices-in-pytorc/65584479#65584479\n",
    "        events = np.array(self.events_data[int(start):int(finish)], dtype=np.uint16)\n",
    "        mc = 400 # 345 is max dim\n",
    "        img = np.zeros((mc,mc), dtype=np.float32)\n",
    "        np.add.at(img,[events[:,1], events[:,0]], events[:,2] - .5)\n",
    "        events = torch.tensor(img).unsqueeze(0)\n",
    "\n",
    "        return events, dpose\n",
    "\n",
    "    def set_label_delta(self, delta):\n",
    "        self.delta = delta\n",
    "\n",
    "data_dir = \"indoor_forward_9_davis_with_gt\"\n",
    "ENC_SEQ_LEN = 1\n",
    "vio_dataset = EventDataset(data_dir, \"groundtruth.txt\", ENC_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# s = time.time()\n",
    "# for i in range(len(vio_dataset)):\n",
    "#     size = vio_dataset.__getitem__(i)[0].shape[0]\n",
    "# (time.time() - s) / 1000 # per one sample, very quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400, 400])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vio_dataset.__getitem__(1002)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6508, -0.8224,  0.2350,  0.7810, -0.0408, -0.0881,  0.1149]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT(\n",
    "    image_size = 400,\n",
    "    patch_size = 20,\n",
    "    num_classes = 7,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.,\n",
    "    channels=1\n",
    ")\n",
    "\n",
    "img = vio_dataset.__getitem__(1002)[0].unsqueeze(0) # batch 1\n",
    "\n",
    "preds = model(img) # (1, 10)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 400, 400])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "dataloader = torch.utils.data.DataLoader(vio_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "next(iter(dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html training loop from here\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(vio_dataset)\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vio_dataset.set_label_delta(10)\n",
    "# events = np.array(vio_dataset.__getitem__(1002)[0], dtype=np.uint16)\n",
    "# mc = int(events.max())\n",
    "# img = np.zeros((mc+1,mc+1))\n",
    "# np.add.at(img,[events[:,1], events[:,0]], events[:,2] - .5)\n",
    "# # img[events[:,1],events[:,0]] += (events[:,2] - .5)\n",
    "# plt.imshow(img), img.max()\n",
    "# test = np.zeros((3,3))\n",
    "# index = [[1,1],[0,0]]\n",
    "# values = [1,1]\n",
    "# np.add.at(test,index,values)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IMUTransformer(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         encoder_layer = nn.TransformerEncoderLayer(d_model=3, nhead=3, dim_feedforward=8, batch_first=True)\n",
    "#         transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "#         self.encoder = transformer_encoder\n",
    "#         self.fc1 = nn.Linear(in_features=3, out_features=8)\n",
    "#         self.fc2 = nn.Linear(in_features=8, out_features=7)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.encoder(x))\n",
    "#         x = torch.relu(self.fc1(x[:,-1,:]))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# model = IMUTransformer()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# dataloader = torch.utils.data.DataLoader(vio_dataset, batch_size=4, shuffle=True, num_workers=4) # 4 might work :?)\n",
    "# next(iter(dataloader))[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

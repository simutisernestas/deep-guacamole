{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\r\n",
    "import torch\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "from torchvision.io import read_image\r\n",
    "from torchvision import datasets\r\n",
    "from torch.utils.data import Dataset\r\n",
    "from torchvision.transforms import ToTensor\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "from torchvision import transforms\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "import transforms3d as tf\r\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPickle():\r\n",
    "    stereo_left_df = pd.read_csv(\"indoor_forward_9_snapdragon_with_gt/left_images.txt\", delimiter=' ', skiprows=1, names=[\"id\", \"timestamp\", \"image_name\"], index_col=False) \r\n",
    "    labels_df = pd.read_csv(\"indoor_forward_9_snapdragon_with_gt/groundtruth.txt\", delimiter=' ', skiprows=1, names=[\"timestamp\", \"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\", \"img_start_idx\"])\r\n",
    "    for i in range(len(labels_df)):\r\n",
    "        minid = abs(stereo_left_df[\"timestamp\"]-labels_df.iloc[i][\"timestamp\"]).idxmin()\r\n",
    "        labels_df[\"img_start_idx\"][i] = minid\r\n",
    "    labels_df.to_pickle(\"./stereo_indexed_labels.pickle\")\r\n",
    "createPickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "Creaing tensors\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "Stacking tensors\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "class StereoDataset(Dataset):\r\n",
    "    def __init__(self, data_dir, label_delta_len):\r\n",
    "        self.stereo_data = self.preprocess_images()\r\n",
    "\r\n",
    "        self.labels_df = pd.read_pickle(\"./stereo_indexed_labels.pickle\")\r\n",
    "        labels_df_nostamp = self.labels_df.loc[:, self.labels_df.columns != 'timestamp']\r\n",
    "        labels_df_nostamp = labels_df_nostamp.loc[:, labels_df_nostamp.columns != 'events_start_idx']\r\n",
    "        self.labels = torch.tensor(labels_df_nostamp.to_numpy(), dtype=torch.float32)\r\n",
    "\r\n",
    "        self.delta = label_delta_len\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.labels.shape[0] - self.delta\r\n",
    "\r\n",
    "    def set_label_delta(self, delta):\r\n",
    "        self.delta = delta\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        dpose = torch.zeros(7)\r\n",
    "        l1 = self.labels[idx]\r\n",
    "        l2 = self.labels[idx+self.delta]\r\n",
    "        dl = l2-l1 # position delta\r\n",
    "        dpose[:3] = dl[:3]\r\n",
    "        q1 = l1[3:][[3,0,1,2]] # rearange quaternion, w goes first\r\n",
    "        q2 = l2[3:][[3,0,1,2]] # rearange quaternion, w goes first\r\n",
    "        dq = tf.quaternions.qmult(q2, tf.quaternions.qinverse(q1)) # orientation delta\r\n",
    "        dpose[3:] = torch.tensor(dq, dtype=torch.float32) # pose delta is the label\r\n",
    "\r\n",
    "        start = self.labels_df.iloc[idx][\"img_start_idx\"]\r\n",
    "        finish = self.labels_df.iloc[idx+self.delta][\"img_start_idx\"]\r\n",
    "\r\n",
    "        # could highly optimize this : )\r\n",
    "        # torch version https://stackoverflow.com/questions/65584330/add-a-index-selected-tensor-to-another-tensor-with-overlapping-indices-in-pytorc/65584479#65584479\r\n",
    "        events = np.array(self.stereo_data[int(start):int(finish)], dtype=np.uint16)\r\n",
    "        print(events)\r\n",
    "        mc = 400 # 345 is max dim\r\n",
    "        img = np.zeros((mc,mc), dtype=np.float32)\r\n",
    "\r\n",
    "        np.add.at(img,tuple([events[:,1], events[:,0]]), events[:,2] - .5)\r\n",
    "        events = torch.tensor(img).unsqueeze(0)\r\n",
    "\r\n",
    "        return events, dpose\r\n",
    "\r\n",
    "\r\n",
    "    def preprocess_images(self):\r\n",
    "        data_dir = \"indoor_forward_9_snapdragon_with_gt/\"\r\n",
    "        img_annot_cols=[\"stamp\",\"name\",\"none\"]\r\n",
    "        left_images = pd.read_csv(data_dir + \"left_images.txt\", delimiter=' ', skiprows=1, names=img_annot_cols)\r\n",
    "        right_images = pd.read_csv(data_dir + \"right_images.txt\", delimiter=' ', skiprows=1, names=img_annot_cols)\r\n",
    "        images = []\r\n",
    "\r\n",
    "        print(\"Preprocessing images\")\r\n",
    "        for idx, i in enumerate(zip(left_images['name'], right_images['name'])):\r\n",
    "            if idx % 100 == 0:\r\n",
    "                print(idx)\r\n",
    "            left_image = Image.open(data_dir + i[0])\r\n",
    "            right_image = Image.open(data_dir +  i[1])\r\n",
    "            left_image = left_image.resize((160,120))\r\n",
    "            right_image = right_image.resize((160,120))\r\n",
    "            concat = Image.new('L', (left_image.width + right_image.width, left_image.height))\r\n",
    "            concat.paste(left_image, (0,0))\r\n",
    "            concat.paste(right_image, (left_image.width,0))\r\n",
    "            images.append(concat)\r\n",
    "\r\n",
    "        tensors = []\r\n",
    "        convert_tensor = transforms.ToTensor()\r\n",
    "        print(\"Creaing tensors\")\r\n",
    "        for i, v in enumerate(images):\r\n",
    "            if i % 100 == 0:\r\n",
    "                print(i)\r\n",
    "            tensors.append(convert_tensor(v))\r\n",
    "\r\n",
    "        print(\"Stacking tensors\")\r\n",
    "        output = []\r\n",
    "        for i in range(2, len(tensors)):\r\n",
    "            if i % 100 == 0:\r\n",
    "                print(i)            \r\n",
    "            output.append(torch.stack(tensors[i-2:i+1]))\r\n",
    "\r\n",
    "        return output\r\n",
    "\r\n",
    "data_dir = \"indoor_forward_9_davis_with_gt\"\r\n",
    "vio_dataset = StereoDataset(data_dir, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msj\\AppData\\Local\\Temp\\ipykernel_32096\\1321389286.py:34: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  events = np.array(self.stereo_data[int(start):int(finish)], dtype=np.uint16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (61,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m vio_dataset\u001b[38;5;241m.\u001b[39mset_label_delta(\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[43mvio_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(events)\n",
      "Cell \u001b[1;32mIn [29], line 34\u001b[0m, in \u001b[0;36mStereoDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m finish \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_df\u001b[38;5;241m.\u001b[39miloc[idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_start_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# could highly optimize this : )\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# torch version https://stackoverflow.com/questions/65584330/add-a-index-selected-tensor-to-another-tensor-with-overlapping-indices-in-pytorc/65584479#65584479\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstereo_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(events)\n\u001b[0;32m     36\u001b[0m mc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m \u001b[38;5;66;03m# 345 is max dim\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (61,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "vio_dataset.set_label_delta(100)\r\n",
    "events = vio_dataset.__getitem__(1000)[0].squeeze(0)\r\n",
    "plt.imshow(events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python380jvsc74a57bd098eb5d3a94249cb0db76253c0c42090f3bf8601eeb1b84377b75a54af4000e03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "98eb5d3a94249cb0db76253c0c42090f3bf8601eeb1b84377b75a54af4000e03"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}